* [안정 해시 설계](#--------)
* [해시 키 재배치(rehash) 문제](#---------rehash----)
* [안정 해시](#-----)
    + [해시 공간과 해시 링](#-----------)
    + [해시 서버](#-----)
    + [해시 키](#----)
* [서버 조회](#-----)
    + [서버 추가](#-----)
    + [서버 제거](#-----)
    + [기본 구현법의 두 가지 문제](#---------------)
    + [가상 노드](#-----)
    + [재배치할 키 결정](#---------)
* [마치며](#---)

- [키-값 저장소 설계](#----------)
    * [문제 이해 및 설계 범위 확정](#----------------)
    * [단일 서버 키-값 저장소](#-------------)
    * [분산 키-값 저장소](#----------)
        + [CAP 정리](#cap---)
            - [이상적 상태](#------)
            - [실세계의 분산 시스템](#-----------)
        + [시스템 컴포넌트](#--------)
            - [데이터 파티션](#-------)
            - [데이터 다중화](#-------)
            - [데이터 일관성](#-------)
                * [일관성 모델](#------)
                * [비 일관성 해소 기법 : 데이터 버저닝](#---------------------)
                * [장애 처리](#-----)
                * [장애 감지](#-----)
                * [일시적 장애 처리](#---------)
                * [영구 장애 처리](#--------)
                * [데이터 센터 장애 처리](#------------)
            - [시스템 아키텍처 다이어그램](#--------------)
            - [쓰기 경로](#-----)
            - [읽기 경로](#-----)
    * [요약](#--)

## 안정 해시 설계

## 해시 키 재배치(rehash) 문제

- N개의 서버에 부하를 균등하게 나누는 보편적인 방법은 해시 함수를 사용하는 것
- 이는 서버 풀의 크기가 고정되어 있을 때, 데이터 분포가 균등할 때는 잘 작동하지만 서버의 수가 바뀔 때 문제가 생긴다
- 이는 대부분의 키를 재분배시킨다

## 안정 해시

- 안정 해시(consistent hash)는 해시 테이블의 크기가 조정될 때 평균적으로 k/n개의 키만 재배치하는 해시 기술이다
    - k : 키의 개수
    - n : 슬롯의 개수

### 해시 공간과 해시 링

![](files/PixelSnap%202024-02-06%20at%2022.03.15@2x.png)

### 해시 서버

- 해시 함수 f를 사용해 서버를 해시 링 위에 배치할 수 있다

![](files/PixelSnap%202024-02-06%20at%2022.04.18@2x.png)

### 해시 키

![](files/PixelSnap%202024-02-06%20at%2022.04.24@2x.png)

- 해시 함수와 무관하게 캐시할 키 또한 해시 링 위에 배치할 수 있다

## 서버 조회

![](files/PixelSnap%202024-02-06%20at%2022.04.42@2x.png)

- 어떤 키가 저장되는 서버는, 해당 키의 위치로부터 시계 방향으로 링을 탐색해 나가면서 만나는 첫 번째 서버다

### 서버 추가

![](files/PixelSnap%202024-02-06%20at%2022.05.09@2x.png)

- 서버가 추가되어도 대부분의 키는 그대로이고, 일부 키들만 재배치된다

### 서버 제거

![](files/PixelSnap%202024-02-06%20at%2022.05.33@2x.png)

- 서버가 제거되었을 때도 마찬가지다

### 기본 구현법의 두 가지 문제

![](files/PixelSnap%202024-02-06%20at%2022.05.48@2x.png)

- 처음 제안된 안정 해시 알고리즘은 다음과 같다
    - 서버와 키를 균등 분포 해시 함수를 사용해 해시 링 위에 배치한다
    - 키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버이다

- 이는 두 가지 문제가 있다
    - 서버가 추가되고 삭제되는 상황에서 파티션의 크기를 균등하게 유지하는 것이 불가능하다
        - 파티션은 인접한 서버 사이의 해시 공간
    - 또 다른 문제는 키의 균등 분포를 달성하기 어렵다는 것이다

![](files/PixelSnap%202024-02-06%20at%2022.06.53@2x.png)

- 대부분의 키가 서버 2에 보관되는 것을 알 수 있다

- 이러한 문제를 해결하기 위해 제안된 기법이 가상 노드(virtual node) 또는 복제(replica)라고 불리는 기법이다

### 가상 노드

- 가상 노드(virtual node)는 실제 노드 또는 서버를 가리키는 노드
- 하나의 서버는 링 위에 여러 개의 가상 노드를 가질 수 있다

![](files/PixelSnap%202024-02-06%20at%2022.08.32@2x.png)
![](files/PixelSnap%202024-02-06%20at%2022.08.36@2x.png)

- 가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등해진다
- 100 ~ 200 개의 가상 노드를 사용했을 경우 표준 편차 값은 평균의 5%에서 10% 사이다
- 가상 노드의 개수를 더 늘리면 표준 편차의 값은 떨어지지만 가상 노드 데이터를 저장할 공간은 더 많이 필요하다
    - 즉, 트레이드 오프가 있으므로 적당한 값 결정 필요

### 재배치할 키 결정

![](files/PixelSnap%202024-02-06%20at%2022.09.45@2x.png)

- 서버 4가 추가되었다면 영향 범위는 s4부터 그 반시계 방향에 있는 첫 번째 서버 s3까지다
    - 즉, s3부터 s4 사이에 있는 키를 s4로 재배치

![](files/PixelSnap%202024-02-06%20at%2022.12.33@2x.png)

- s1이 삭제되면 s1부터 s0 사이의 키들을 s2로 재배치해야한다

## 마치며

- 서버가 추가되거나 삭제될 때 재배치되는 키의 수 최소화
- 데이터가 보다 균등 분포되므로 수평적 규모 확장성을 달성하기 쉽다
- 핫스팟(hotspot) 키 문제를 줄인다
    - 안정 해시는 데이터를 좀 더 균등하게 분배해 이런 문제에 대한 가능성을 줄인다

- 안정 해시는 다음에 쓰인다
    - DynamoDB 파티셔닝 관련 컴포넌트
    - Apache Cassandra 클러스터에서의 데이터 파티셔닝
    - Discord
    - Akamai CDN
    - Meglev 네트워크 부하 분산기

[Jump consistent hash](https://www.popit.kr/jump-consistent-hash/)

[Consistent Hashing 에 대한 기초](https://www.popit.kr/consistent-hashing/)

# 키-값 저장소 설계

- 이 저장소에 저장되는 값은 고유 식별자(identifier)를 키롤 가져야 한다
- 키와 값 사이의 이런 연결 관계를 키-값 쌍이라고 지칭한다

- 키-값 쌍에서 키는 유일해야 하며, 해당 키에 매달린 값은 키를 통해서만 접근할 수 있다
- 키는 일반 텍스트일 수도 있고 해시 값일 수도 있다
- 성능상의 이유로 키는 짧을수록 좋다

- 키-값 쌍에서 값은 무엇이 오든 상관하지 않는다

## 문제 이해 및 설계 범위 확정

- 완벽한 설계는 없으므로 읽기, 쓰기 그리고 메모리 사용량 사이에 어떤 균형을 찾고, 데이터의 일관성과 가용성 사이에서 타협적 결정을 내린 설계를 만들어야 한다

- 여기서는 다음 특성을 갖는 키-값 저장소를 설계한다
    - 키-값 쌍의 크기는 10KB 이하
    - 큰 데이터 저장 가능
    - 높은 가용성 제공
        - 시스템은 설사 장애가 있더라도 빨리 응답
    - 높은 규모 확장성 제공
        - 트래픽 양에 따라 자동적으로 서버 증설/삭제
    - 데이터 일관성 수준은 조정 가능해야 한다
    - 응답 지연시간이 짧아야 한다

## 단일 서버 키-값 저장소

- 한 대 서버만 사용하는 키-값 저장소 설계는 쉽다
- 가장 직관적인 방법은 메모리에 해시 테이블로 저장하는 것
    - 이는 빠른 속도르 자랑
    - 그러나 현실적으로 모든 데이터를 메모리에 두는 것은 불가능
- 이에 대한 개선책은 다음 등이 있다
    - 데이터 압축
    - 자주 쓰이는 데이터만 메모리에 두고 나머지 디스크에 저장
- 이렇게 하더라도 한 대의 서버로는 부족한 시점은 온다

## 분산 키-값 저장소

- 분산 해시 테이블이라고도 불린다
- 키-값 쌍을 여러 서버에 분산시키는 탓이다

### CAP 정리

- 데이터 일관성(Consistency)
    - 모든 클라이언트는 어떤 노드에 접속하든 같은 데이터를 본다
- 가용성(Availability)
    - 일부 노드에 장애가 발생하더라도 항상 응답을 받을 수 있다
- 파티션 감내성(Partition tolerance)
    - 두 노드 사이에 통신 장애가 발생하더라도 시스템은 계속 동작한다

- 세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능
- 따라서 두 가지를 선택해야 하며, 이를 아래와 같이 분류 가능
    - CP 시스템
        - 가용성을 희생
    - AP 시스템
        - 데이터 일관성을 희생
    - CA 시스템
        - 파티션 감내를 희생
        - 통상적으로 네트워크 장애는 피할 수 없으므로 보통 분산 시스템은 파티션 문제를 감내할 수 있도록 설계되어야 한다
        - 따라서 CA 시스템은 존재 X

#### 이상적 상태

![](files/PixelSnap%202024-02-06%20at%2022.42.43@2x.png)

- 이상적 환경에서는 네트워크가 파티션되는 상황은 일어나지 않는다
- 따라서 n1에 기록된 데이터는 자동적으로 n2, n3에 복제된다
- 데이터 일관성과 가용성도 만족된다

#### 실세계의 분산 시스템

![](files/PixelSnap%202024-02-06%20at%2022.43.24@2x.png)

- 분산 시스템은 파티션 문제를 피할 수 없다
- 파티션 문제가 발생하면 일관성과 가용성 사이에서 하나를 선택해야 한다

- 위 그림은 n3에 장애가 발생해 n1 및 n2와 통신할 수 없는 상황
- n1 또는 n2에 기록된 데이터는 n3에 전달되지 않으므로 n1 또는 n2에 기록된 데이터는 n3에 전달되지 않는다
- n3에 기록되었으나 n1 및 n2로 전달되지 않은 데이터가 있다면 n1, n2는 오래된 사본을 갖고 있을 것이다

- 가용성 대신 일관성을 선택한다면(CP 시스템) 서버 사이에 생길 수 있는 데이터 불일치 문제를 피하기 위해 n1과 n2에 대한 쓰기 연산을 중단시켜야 한다
    - 이렇게 하면 가용성이 깨진다
    - 보통 은행권 시스템이 이를 택한다

- 일관성 대신 가용성을 선택하다면(AP 시스템) 낡은 데이터를 반환할 위험이 있다고 하더라도 계속 읽기 연산을 허용해야 한다
- 파티션 문제가 해결된 뒤에 새 데이터를 n3에 전송한다

- 분산 키-값 저장소를 만들 때는 요구사항에 맞게 CAP 정리를 적용하자
    - 이는 면접관과 상의 필요

### 시스템 컴포넌트

- 여기서는 키-값 저장소 구현에 사용될 핵심 컴포넌트 및 기술들을 살펴본다
    - 데이터 파티션
    - 데이터 다중화(replication)
    - 일관성(conistency)
    - 일관성 불일치 해소(inconsistency resolution)
    - 장애 처리
    - 시스템 아키텍처 다이어그램
    - 쓰기 경로 (write path)
    - 읽기 경로(read path)

#### 데이터 파티션

- 대규모 애플리케이션의 경우 전체 데이터를 한 대 서버에 다 넣는 것은 불가능
- 가장 단순한 해결책은 데이터를 작은 파티션 단위로 분할한 다음 여러 대의 서버에 저장하는 것
- 다음을 고려
    - 데이터를 여러 서버에 고르게 분산할 수 있는가
    - 노드가 추가되거나 삭제될 때 데이터의 이동을 최소화할 수 있는가

- 안정 해시(consistent hash)가 이런 문제를 푸는 데 적합한 기술이다
    - 규모 확장 자동화(automatic scaling)
        - 시스템 부하에 맞게 서버 추가 및 삭제 가능
    - 다양성(heterogeneity)
        - 서버의 용량에 맞게 가상 노드의 수를 조정할 수 있다

#### 데이터 다중화

- 높은 가용성과 안정성 확보를 위해서는 데이터를 N개 서버에 **비동기적**으로 다중화할 필요가 있다
    - N은 튜닝 가능한 값
- 가상 노드를 사용하는 경우 선택한 N개의 노드에 대응되는 실제 물리 서버의 개수가 N개보다 작아질 수 있으므로 같은 물리 서버를 중복 선택하지 않도록 해야 한다

- 같은 데이터 센터에 속한 노드는 문제를 동시에 겪을 수 있으므로 이를 분릴해야 한다

#### 데이터 일관성

- 여러 노드에 다중화된 데이터는 적절히 동기화되어야 한다
- 정족수 합의(quorum consensus) 프로토콜을 사용하면 읽기/쓰기 연산에 모두 일관성을 보장할 수 있다

- N : 사본 개수
- W : 쓰기 연산에 대한 정족수
- R : 읽기 연산에 대한 정족수

![](files/PixelSnap%202024-02-07%20at%2021.32.15@2x.png)

- W가 1이라고 데이터가 한 대 서버에만 기록되는 것이 아니다
- 쓰기 연산이 성공했다고 판단하기 위해 coordinator가 받아야 하는 최소 응답의 개수다

- W, R, N의 값은 응답 지연과 데이터 일관성 사이의 타협점이다
- W = 1 또는 R = 1인 값은 응답 속도는 빠르지만 일관성이 떨어진다
- W + R > N인 경우에 강한 일관성(strong consistency)가 보장된다

- R = 1, W = N : 빠른 읽기 연산에 최적화된 시스템
- W = 1, R = N : 빠른 쓰기 연산에 최적화된 시스템
- W + R > N : 강한 일관성이 보장됨 (보통 N = 3, W = R = 2)
- W + R <= N : 강한 일관성 보장 X

##### 일관성 모델

- 일관성 모델은 데이터의 일관성 수준을 조정
    - 강한 일관성(strong consistency)
        - 모든 읽기 연산은 가장 최근에 갱신된 결과를 반환
    - 약한 일관성(weak consistency)
        - 읽기 연산은 가장 최근에 갱신된 결과를 반환하지 못할 수도 있다
    - 최종 일관성(eventual consistency)
        - 약한 일관성의 한 형태로, 갱신 결과가 결국에는 모든 사본에 반영된다

- 강한 일관성을 달성하는 일반적인 방법은 모든 사본에 현재 쓰기 연산 결과가 반영될 때까지 해당 데이터에 대한 읽기/쓰기를 금지하는 것
    - 그러나 이는 고가용성 시스템에 적합 X
- 따라서 다이나모 또는 카산드라와 같은 저장소는 최종 일관성 모델을 택한다

- 최종 일관성 모델의 경우 쓰기 연산이 병렬적으로 발생하면 시스템에 저장된 값의 일관성이 깨질 수 있는데 이는 클라이언트가 해결해야 한다
    - Soft State
- 클라이언트는 데이터의 버전 정보를 활용해 일관성이 깨진 데이터를 읽지 않도록 한다

##### 비 일관성 해소 기법 : 데이터 버저닝

- 데이터를 다중화하면 가용성은 높아지지만 사본 간 일관성이 깨질 가능성이 높아진다
- 버저닝(versioning)과 벡터 시계(vector clock)는 이를 해결한다
- 버저닝은 데이터를 변경할 때마다 해당 데이터의 새로운 버전을 만든다
    - 각 버전의 데이터는 불변

![](files/PixelSnap%202024-02-07%20at%2021.39.21@2x.png)

- 각 서버가 값을 변경하는 경우 버전 충돌 발생
- 이 문제를 해결하기 위해서는 충돌을 발견하고, 자동으로 해결해 낼 버저닝 시스템이 필요하다
- 벡터 시계(vector clock)은 이런 문제를 푸는데 보편적으로 사용된다

- 벡터 시계는 [서버, 버전] 순서쌍을 데이터에 매단 것이다
    - D([S1, v1], [S2, v2], ..., [Sn, vn])과 같이 표현
    - D는 데이터, vi는 버전 카운터, Si는 서버 번호
- D를 서버 Si에 기록하려면 다음 작업 중 하나를 해야한다
    - [Si, vi]가 있으면 vi를 증가
    - 그렇지 않으면 새 항목 [Si, v1] 만든다

![](files/PixelSnap%202024-02-07%20at%2021.57.04@2x.png)

- 어떤 클라이언트가 D3, D4를 읽으면 데이터 간 충돌이 있다는 걸 알게 된다
- 이 충돌은 클라이언트가 해소한 후에 서버에 기록한다
    - 이를 처리한 서버가 Sx

- 벡터 시계를 사용하면 어떤 버전 X가 버전 Y의 이전 버전인지 쉽게 판단할 수 있다
- 버전 Y에 포함된 모든 구성요소의 값이 X에 포함된 모든 구성요소 값보다 같거나 큰지만 보면 된다

- 벡터 시계를 사용해 충돌을 감지하고, 해소하는 방법에는 2가지 단점이 있다
    - 충돌 감지 및 해소 로직이 클라이언트에 들어가 구현이 복잡해진다
    - [서버:버전] 순서쌍 개수가 굉장히 빠르게 늘어난다
        - 따라서 임계치를 설정하고, 임계치 이상으로 길어지면 오래된 순서쌍을 벡터 시계에서 제거해야 한다
        - 하지만 이렇게 하면 선후 관계가 정확하게 결정될 수 없기 때문에 충돌 해소 과정의 효율성이 낮아진다
        - 하지만 다이나모 논문에 따르면 아마존은 실제로 그런 문제를 발견한 적이 없다고 한다

##### 장애 처리

##### 장애 감지

- 분산 시스템에서는 한 대의 서버가 서버 A가 죽었다고 말해도 장애 처리하지 않는다
- 보통 두 대 이상의 서버가 똑같이 서버 A의 장애를 보고해야 장애가 발생했다고 간주한다

![](files/PixelSnap%202024-02-07%20at%2022.00.43@2x.png)

- 위 그림처럼 멀티캐스팅 채널을 구축하는 게 가장 손쉬운 방법이지만 서버의 수가 늘어나면 비효율적이다

- 가십 프로토콜(gossip protocol) 같은 분산형 장애 감지(decentralized failure detection) 솔루션을 채택하는 편이 효율적이다
    - 각 노드는 멤버십 목록을 유지한다. 멤버십 목록은 각 멤버 ID와 heartbeat counter 쌍의 목록이다
    - 각 노드는 주기적으로 자신의 heartbeat counter를 증가시킨다
    - 각 노드는 무작위로 선정된 노드들에게 주기적으로 자신의 heartbeat counter 목록을 보낸다
    - heartbeat counter 목록을 받은 노드는 멤버십 목록을 최신 값으로 갱신한다
    - 어떤 멤버의 heartbeat counter 값이 지정된 시간 동안 갱신되지 않으면 해당 멤버는 장애 상태인 것으로 간주한다

![](files/PixelSnap%202024-02-07%20at%2022.03.57@2x.png)

- s0은 s2의 카운터가 오랫동안 증가되지 않았다는 것을 발견
- s0은 s2를 포함한 카운터 목록을 무작위로 선택된 노드에게 전달한다
- s2의 카운터가 오랫동안 증가되지 않았음을 발견한 모든 노드는 해당 노드를 장애 노드로 표시한다

##### 일시적 장애 처리

- 가십 프로토콜로 장애를 감지한 시스템은 가용성을 보장하기 위해 필요한 조치를 해야 한다
- 엄격한 정족수(strict quorum) 접근법을 사용한다면 읽기와 쓰기 연산을 금지해야 한다
- 느슨한 정족수(sloppy quorum) 접근법은 쓰기 연산을 수행할 W개의 건강한 서버와 읽기 연산을 수행할 R개의 건강한 서버를 해시 링에서 고른다

- 네트워크나 서버 문제로 장애 상태인 서버로 가는 요청은 다른 서버가 잠시 맡는다
- 그동안 발생한 변경사항은 해당 서버가 복구되었을 때 일괄 반영해 데이터 일관성을 보존한다
    - 이를 위해 임시로 쓰기 연산을 처리한 서버는 그에 대한 hint를 남겨둔다
    - 이를 hinted handoff 기법이라고 한다

![](files/PixelSnap%202024-02-07%20at%2022.07.09@2x%201.png)

- 장애 상태인 s2에 대한 읽기 및 쓰기 연산은 일시적으로 s3가 처리하며, s3가 복구되면 s3는 갱신된 데이터를 s2로 보낸다

##### 영구 장애 처리

- hinted handoff는 일시적 장애를 처리하기 위한 기법이다
- 영구적인 장애에 대해서는 anti-entropy 프로토콜을 구현해 사본들을 동기화한다
- anti-entropy 프로토콜은 사본들을 비교해 최신 버전으로 갱신하는 과정을 포함한다

- 일관성이 망가진 상태를 탐지하고, 전송 데이터의 양을 줄이기 위해서 Merkle 트리를 사용한다

- Merkle Tree는 각 노드에 자식 노드들의 레이블로부터 계산된 해시 값을 레이블로 두어 대규모 자료 구조의 내용을 효과적이면서도 보안상 안전한 방법으로 검증할 수 있다

![](files/PixelSnap%202024-02-07%20at%2022.09.30@2x.png)

- Merkle Tree를 사용하면 동기화해야 하는 데이터의 양은 실제로 존재하는 차이의 크기에 비례할 뿐, 두 서버에 보관된 데이터의 총량과는 무관해진다

##### 데이터 센터 장애 처리

- 데이터 센터 장애에 대응할 수 있는 시스템을 구성하기 위해서는 데이터를 여러 데이터 센터에 다중화하는 것이 중요하다

#### 시스템 아키텍처 다이어그램

![](files/PixelSnap%202024-02-07%20at%2022.10.33@2x.png)

- 노드는 자동으로 추가 또는 삭제할 수 있으므로 시스템은 완전히 분산된다
- 데이터는 여러 노드에 다중화된다
- 모든 노드가 같은 책임을 지므로, SPOF는 존재하지 않는다

- 완전히 분산된 설계를 채택했으므로 모든 노드는 아래와 같은 기능을 전부 지원해야 한다
    - 클라이언트 API
    - 장애 감지
    - 데이터 충돌 해소
    - 장애 복구 메커니즘
    - 다중화
    - 저장소 엔진
    - ...

#### 쓰기 경로

![](files/PixelSnap%202024-02-07%20at%2022.11.34@2x.png)

- 쓰기 요청이 커밋 로그에 기록된다
- 데이터가 메모리 캐시에 기록된다
- 메모리 캐시가 가득차거나 사전에 정의된 어떤 임계치에 도달하면 데이터는 디스크에 있는 SSTable에 기록된다
    - Sorted-String Table
    - <키, 값> 쌍의 순서쌍을 정렬한 리스트 형태로 관리하는 테이블

#### 읽기 경로

- 읽기 요청을 받은 노드는 데이터가 메모리 캐시에 있는지부터 살핀다
- 있는 경우 데이터를 클라이언트에게 반환
- 없다면 디스크로부터 가져와야 한다
    - 데이터가 어느 SSTable에 있을까?
    - Bloom filter를 사용해서 찾는다

![](files/PixelSnap%202024-02-07%20at%2022.12.59@2x.png)

![](files/PixelSnap%202024-02-07%20at%2022.13.04@2x.png)

## 요약

- 대규모 데이터 저장
    - 안정 해시를 사용해 서버들에 부하 분산
- 읽기 연산에 대한 높은 가용성 보장
    - 데이터를 여러 데이터센터에 다중화
- 쓰기 연산에 대한 높은 가용성 보장
    - 버저닝 및 벡터 시계를 사용한 충돌 해소
- 데이터 파티션
    - 안정 해시
- 점진적 규모 확장성
    - 안정 해시
- 다양성(heterogeneity)
    - 안정 해시
- 조절 가능한 데이터 일관성
    - 정족수 합의(quorum consensus)
- 일시적 장애 처리
    - 느슨한 정족수 프로토콜(sloppy quorum)과 단서 후 임시 위탁(hinted handoff)
- 영구적 장애 처리
    - 머클 트리(Merkle tree)
- 데이터 센터 장애 대응
    - 여러 데이터 센터에 걸친 데이터 다중화
